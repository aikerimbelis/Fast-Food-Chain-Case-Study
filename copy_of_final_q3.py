# -*- coding: utf-8 -*-
"""copy-of-final-q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/aikerimbelis/4c31dae46505838bb1d3f96eb56d88d9/copy-of-final-q3.ipynb

Final q3
"""



import pandas as pd # for data handling
from sklearn.model_selection import cross_val_score # for cross-validation
from sklearn.metrics import accuracy_score, classification_report # evaluation metrics
import matplotlib.pyplot as plt # for plotting

# scikit-learn classifiers evaluated (change as desired)
from sklearn.naive_bayes import GaussianNB 
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier

from google.colab import drive
drive.mount('/content/drive')

! unzip '/content/drive/MyDrive/final.q3.data.zip'

# Read data from CSV files into pandas dataframes
train = pd.read_csv('final.q3.train.csv') # training data
test = pd.read_csv('final.q3.test.csv') # test data
new = pd.read_csv('final.q3.new.csv') # unlabeled data
# Show number of rows and columns in each dataframe
print('train contains %d rows and %d columns' %train.shape)
print('test contains %d rows and %d columns' %test.shape)
print('new contains %d rows and %d columns' %new.shape)
print('First 3 rows in train:') 
train.head(3) # display first 3 training samples

print('Last 2 rows in new:') 
new.tail(2) # display last 2 unlabeled samples

features = list(train)[1:] # all but the first column header are feature names
print("features:", features)
X_train, X_test, X_new = train[features], test[features], new[features]
y_train, y_test = train.y, test.y
print('Shapes:')
print(f'X_train: {X_train.shape}, X_test: {X_test.shape}, X_new: {X_new.shape}')
print(f'y_train: {y_train.shape}, y_test: {y_test.shape}')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model = GaussianNB() # change hyperparameters as desired
# score = cross_val_score(model, X_train, y_train, cv=4).mean() # mean cross-validation accuracy
# print(f'Mean cross-validation accuracy = {score:0.4f}')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model = DecisionTreeClassifier(max_leaf_nodes=10) # change hyperparameters as desired
# score = cross_val_score(model, X_train, y_train, cv=4).mean() # mean cross-validation accuracy
# print(f'Mean cross-validation accuracy = {score:0.4f}')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model = RandomForestClassifier(n_estimators=100) # change hyperparameters as desired
# score = cross_val_score(model, X_train, y_train, cv=4).mean() # mean cross-validation accuracy
# print(f'Mean cross-validation accuracy = {score:0.4f}')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model = ExtraTreesClassifier(n_estimators=100) # change hyperparameters as desired
# score = cross_val_score(model, X_train, y_train, cv=4).mean() # mean cross-validation accuracy
# print(f'Mean cross-validation accuracy = {score:0.4f}')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model = KNeighborsClassifier(n_neighbors=9, algorithm='brute') # change hyperparameters as desired
# score = cross_val_score(model, X_train, y_train, cv=4).mean() # mean cross-validation accuracy
# print(f'Mean cross-validation accuracy = {score:0.4f}')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model = LogisticRegression(max_iter=10000) # change hyperparameters as desired
# score = cross_val_score(model, X_train, y_train, cv=4).mean() # mean cross-validation accuracy
# print(f'Mean cross-validation accuracy = {score:0.4f}')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model = SVC(C=1.0) # change hyperparameters as desired
# score = cross_val_score(model, X_train, y_train, cv=4).mean() # mean cross-validation accuracy
# print(f'Mean cross-validation accuracy = {score:0.4f}')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model = MLPClassifier(hidden_layer_sizes=100, max_iter=1000) # change hyperparameters as desired
# score = cross_val_score(model, X_train, y_train, cv=4).mean() # mean cross-validation accuracy
# print(f'Mean cross-validation accuracy = {score:0.4f}')

for c in [0.01, 0.1]: # number of rules
    model = SVC(C=c)
    score = cross_val_score(model, X_train, y_train, cv=4).mean() # mean cross-validation accuracy
    print(f'Mean cross-validation accuracy with C = {c:0.1f} = {score:0.4f}')

chosen_model = SVC(C=10) # chosen model
print(chosen_model) # display model parameters

# Commented out IPython magic to ensure Python compatibility.
# %%time
# chosen_model.fit(X_train, y_train) # train selected model on ALL training examples
# predicted = chosen_model.predict(X_test) # predicted churn for test examples
# acc = accuracy_score(y_test, predicted) # accuracy on test samples
# print(f'Accuracy on test samples = {acc:0.4f}') # show test accuracy
# print("Classification report on test samples:") # for precision, recall, F1-score
# print(classification_report(y_test, predicted, digits=4)) # rounded to 4 decimal places

predicted_new = chosen_model.predict(X_new) # predicted classes for unlabeled samples
churn_prediction = pd.DataFrame() # dataframe with predicted classes
churn_prediction['ID'] = new.ID # identifiers for unlabeled samples
churn_prediction['y'] = predicted_new # # predicted classes for unlabeled samples
churn_prediction.to_csv('final.q3.prediction.csv', index=False) # save as CSV file
churn_prediction # display results

from sklearn.metrics._plot.confusion_matrix import confusion_matrix
cm = pd.DataFrame(confusion_matrix(y_test, predicted))
cm.to_csv('hw2.q2.cm.csv')
cm

chosen_model.get_params()